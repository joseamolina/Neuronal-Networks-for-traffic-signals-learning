#Ejercicio realizador por Albert Jimenez y José Ángel Molinaimport matplotlib.pyplot as pltimport csvfrom scipy.misc import imresizefrom PIL import Imagefrom numpy import *from pybrain import TanhLayerfrom pybrain.tools.shortcuts import buildNetworkfrom pybrain.datasets import SupervisedDataSet, ClassificationDataSetfrom pybrain.supervised.trainers import BackpropTrainerfrom numpy import shape, argmax, zeros, trace, sum, wherefrom pybrain.datasets            import ClassificationDataSetfrom pybrain.utilities           import percentErrorfrom pybrain.tools.shortcuts     import buildNetworkfrom pybrain.supervised.trainers import BackpropTrainerfrom pybrain.structure.modules   import SoftmaxLayerfrom pylab import ion, ioff, figure, draw, contourf, clf, show, hold, plotfrom scipy import diag, arange, meshgrid, wherefrom numpy.random import multivariate_normalfrom pylab import pausefrom pybrain.tools.xml.networkwriter import NetworkWriterfrom pylab import figure, clf, show, hold, plot, legend, xlabel, ylabel# function for reading the images# arguments: path to the traffic sign data, for example './GTSRB/Training'# returns: list of images, lists of corresponding dimensions, ROIs, and labelsdef readTrafficSigns(rootpath, classes, tracks):    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.    Arguments: path to the traffic sign data, for example './GTSRB/Training'               list of classes to be loaded               dictionary of tracks for each class    Returns:   list of images, list of corresponding dimensions, ROIs,               labels, and filenames'''    images = [] # images    dims = []    ROIs = []    labels = [] # corresponding labels    filenames = []    # loop over the selected classes and tracks    for c in classes:        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file        gtReader.next() # skip header        # loop over all images in current annotations file        for row in gtReader:            filename = row[0]            if tracks[c]== int(filename[0:5]):                images.append(plt.imread(prefix + filename)) # the 1th column is the filename                dims.append((int(row[1]),int(row[2])))                ROIs.append(((int(row[3]),int(row[4])),(int(row[5]),int(row[6]))))                labels.append(row[7]) # the 8th column is the label                filenames.append(filename)        gtFile.close()    return images, dims, ROIs, labels, filenamesdef histeq(im,nbr_bins=256):   #get image histogram   imhist,bins = histogram(im.flatten(),nbr_bins,normed=True)   cdf = imhist.cumsum() #cumulative distribution function   cdf = 255 * cdf / cdf[-1] #normalize   #use linear interpolation of cdf to find new pixel values   im2 = interp(im.flatten(),bins[:-1],cdf)   return im2.reshape(im.shape), cdfdef confmat(fnn,ds):    """Confusion matrix"""    # Add the inputs that match the bias node    inputs = ds['input']    targets = ds['target']    outputs = []    for inpt in inputs:        outputs.append(fnn.activate(inpt))    nclasses = shape(targets)[1]    # 1-of-N encoding    outputs = argmax(outputs,1)    targets = argmax(targets,1)    cm = zeros((nclasses,nclasses))    for i in range(nclasses):        for j in range(nclasses):            cm[i,j] = sum(where(outputs==i,1,0)*where(targets==j,1,0))    print "Confusion matrix is:"    print cm    print "Percentage Correct: ",trace(cm)/sum(cm)*100classes = [3, 7, 13, 14]tracks = {3: 5, 7: 40, 13: 24, 14: 8}trainImages, trainDims, trainROIs, trainLabels, filenames = readTrafficSigns('.', classes, tracks)#DataSet de clasificacionds = ClassificationDataSet(225,1,nb_classes=4)listaClases = ['3','7','13','14']i=0for imagen in trainImages:    tupla1 = trainROIs[i]    tuplaA, tuplaB = tupla1    x1, y1 = tuplaA    x2, y2 = tuplaB    crop_img = imagen[x1:x2,y1:y2,:]            dx ,dy = 15,15    sc_img = imresize(crop_img,(dx,dy,3))        R_img = sc_img[:,:,0]        eq_img, cdf = histeq(R_img)        norm_img = 2*(eq_img-128) / 256        n_im = reshape(norm_img, (1,225))        tipoClase = trainLabels[i]    if tipoClase == listaClases[0]:        ds.addSample(n_im, 0)            elif tipoClase == listaClases[1]:        ds.addSample(n_im, 1)            elif tipoClase == listaClases[2]:        ds.addSample(n_im, 2)        else:        ds.addSample(n_im, 3)        i+=1#Creacion del test y entrenamiento, junto con sus erroreststdata, trndata = ds.splitWithProportion(0.25)tstdata._convertToOneOfMany( )trndata._convertToOneOfMany( )    fnn = buildNetwork( trndata.indim, 12, trndata.outdim, outclass=SoftmaxLayer)trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)#Numero de epocas minimo = 0error1=[]error2=[]#Generamos epoca:lista_epochs = [i for i in range(51)]#entrenamos la red:for elemento in lista_epochs:    trainer.trainEpochs( 1 )    trnresult = percentError( trainer.testOnClassData(),                              trndata['class'] )    tstresult = percentError( trainer.testOnClassData(           dataset=tstdata ), tstdata['class'] )    error1.append(trnresult)    error2.append(tstresult)    print ("epoch: %4d" % trainer.totalepochs, \          "  train error: %5.2f%%" % trnresult, \          "  test error: %5.2f%%" % tstresult)figure(1)clf()   # clear the plotplot(lista_epochs,error1, label='Training')hold(True) # overplot onplot(lista_epochs,error2, label='Testing')legend()xlabel('Epochs')ylabel('percentError')show()confmat(fnn, trndata)NetworkWriter.writeToFile(fnn, 'training.xml')